---
title: "Solution to 2017 M3 Challenge"
output:
  html_notebook: default
  html_document: default
---
```{r}
#install.packages("readxl")
#install.packages("ggplot2")
#install.packages("reshape2")
#install.packages("dplyr")
library(readxl)
library(ggplot2)
library(reshape2)
library(dplyr)
```

This is an outline of a method of solution of the [2017 M3 Challenge](https://m3challenge.siam.org/sites/default/files/uploads/M3%20Challenge%20PROBLEM_2017_0.pdf).  The webpage with all the data is located [here](https://m3challenge.siam.org/node/336).

##Part 1 - Tides of Change
The goal is to build a mathematical model that will classify five national parks in terms of their risk of sea level change (high, medium, or low) over the next 10, 20, and 50 years.

###Step 1 - Understanding the Data

To do so, we first look at the data [NPS_MeanSeaLevel](https://m3challenge.siam.org/sites/default/files/uploads/NPS_MeanSeaLevel_1.xlsx).  We look at the last sheet which contains the 20 years of mean sea level(MSL) data for the 5 national parks.

```{r}
library(readxl)
prob1 <- read_excel("data/NPS_MeanSeaLevel_1.xlsx", "20yr_Monthly_MSL", skip = 3)
colnames(prob1) <- c("Year", "Month", "Acadia", "Cape_Hatteras", "Kenai_Fords", "Olympic","Padre_Island")
prob1
```
It will first be helpful to plot the data.  We first give ourselves a column that measures the number of years since January 1997.
```{r}
prob1$years <- as.numeric(row.names(prob1))/12
prob1
```
Then we can look at a plot of Acadia
```{r}
ggplot(prob1, aes(years, Acadia)) + 
  geom_point(na.rm = TRUE, color = "blue") + 
  labs(title = "Mean Sea Level Trend for Acadia NP", x = "Years since 1/1/1997", y = "Mean Sea Level") +
  theme(plot.title = element_text(hjust = 0.5)) 

```
We can then add a linear fit to it.
```{r}
fit <- lm(Acadia ~ years, prob1)
summary(fit)

```

Notice that this linear fit has a positive slope, `r round(fit$coefficients[2] * 1000,2)` mm/year, and that with such a large t-value, we can say with confidence that it is greater than 0 (i.e. there is a trend of increasing mean sea level in Acadia over the last 20 years).  We can also reinforce this with a look at the 95% confidence interval for the slope in mm/year - (`r 1000*confint(fit, 'years', level=0.95)`).

We can then add this trend line to our plot.
```{r}
ggplot(prob1, aes(years, Acadia)) + 
  geom_point(na.rm = TRUE, color = "orange") + 
  labs(title = "Mean Sea Level Trend for Acadia NP", x = "Years since 1/1/1997", y = "Mean Sea Level") +
  theme(plot.title = element_text(hjust = 0.5)) +
  geom_smooth(method = 'lm', formula = y ~ x, na.rm = TRUE)
```

This slope is slightly different than the one given to us in the Excel file.

```{r}
npsMSL2 <- read_excel("Data/NPS_MeanSeaLevel_1.xlsx", sheet = "MSL_trend")
npsMSL2 <- npsMSL2[1:5,-1]
npsMSL2
```
To recreate their numbers, we need to look at all the historical data from the referenced site for [Station 8413320 ](https://tidesandcurrents.noaa.gov/sltrends/sltrends_station.shtml?stnid=8413320).
```{r}
acadia <- read.csv("https://tidesandcurrents.noaa.gov/sltrends/downloadMeanSeaLevelTrendsCSV.htm?stnid=8413320")
acadia$years <- as.numeric(row.names(acadia))/12
acadia <- acadia[1:1392,] #Removing everything after the previous year
acadia
```
We can plot this.
```{r}
ggplot(acadia, aes(years, Monthly_MSL)) + 
  geom_point(na.rm = TRUE, color = "orange") + 
  labs(title = "Mean Sea Level Trend for Acadia NP", x = "Years since 1/1/1900", y = "Mean Sea Level") +
  theme(plot.title = element_text(hjust = 0.5)) +
  geom_smooth(method = 'lm', formula = y ~ x, na.rm = TRUE)
```
We can look at the linear fit.
```{r}
fit2 <- lm(Monthly_MSL ~ years, acadia)
summary(fit2)

```
This gives a slope of `r round(1000*fit2$coefficients[2],2)` mm/year with a very large t-value.  Again, with certainty, we can say that the sea level is rising at this location.  We can look at the 95% confidence interval for the slope in mm/year - (`r 1000*confint(fit2, 'years', level=0.95)`).  This more closely mirrors the values they gave in the Excel sheet.

We will now look at all the stations.
```{r}
prob1Melt <- melt(prob1, id.vars=c("Year", "Month", "years"), variable.name = "National_Park", value.name = "MSL")
prob1Melt
```

```{r}
ggplot(prob1Melt, aes(years, MSL, color = National_Park)) + 
  geom_point(na.rm = TRUE) + 
  facet_grid(. ~ National_Park) + 
  labs(title = "Mean Sea Level Trend for Various National Parks", x = "Years since 1/1/1997", y = "Mean Sea Level") +
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none") +
  geom_smooth(method = 'lm', formula = y ~ x, na.rm = TRUE, color = "gray40")

```

For further reference, there is a full list of colors for ggplot2 on this [site](http://sape.inf.usi.ch/quick-reference/ggplot2/colour).

Notice that the sea level change at Padre Island doesn't match the increase given in the excel sheet.  To understand this, we can look at the larger data set.

```{r}
#Keep just the data since 1970
mslFull <- acadia[-(1:840),]
mslFull$National_Park <- as.character(npsMSL2[2,2])
for (i in 3:ncol(npsMSL2) ) {
  dfTemp <- read.csv(paste("https://tidesandcurrents.noaa.gov/sltrends/downloadMeanSeaLevelTrendsCSV.htm?stnid=",as.character(as.integer(npsMSL2[1, i])),sep=""))
  dfTemp$National_Park <- as.character(npsMSL2[2,i])
  dfTemp$years <- as.numeric(row.names(dfTemp))/12
  #Keep just the data since 1970
  dfTemp <- dfTemp[-(1:840),]
  mslFull <- rbind(mslFull, dfTemp)
}

ggplot(mslFull, aes(years, Monthly_MSL, color = National_Park)) + 
  geom_point(na.rm = TRUE) + 
  facet_grid(. ~ National_Park) + 
  labs(title = "Mean Sea Level Trend for Various National Parks", x = "Years since 1/1/1970", y = "Mean Sea Level") +
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none") +
  geom_smooth(method = 'lm', formula = y ~ x, na.rm = TRUE, color = "gray40")

```
```{r}
dfLm <- as.data.frame(unique(mslFull$National_Park))
colnames(dfLm) <- c("National_Park")
for(i in 1:nrow(dfLm)){
  dfTemp <- filter(mslFull, National_Park == dfLm$National_Park[i])
  fit3 <- lm(Monthly_MSL ~ years,dfTemp)
  dfLm$Upper_95[i] <- round((1000*confint(fit3, 'years', level=0.95))[2],2)
  dfLm$MSL_Trend_Value[i] <- round(1000*fit3$coefficients[2],2)
  dfLm$Lower_95[i] <- round((1000*confint(fit3, 'years', level=0.95))[1],2)
}
dfLm
```


###Step 2 - Creating the Model - Adlai E Stevenson HS
The [winning solution](https://m3challenge.siam.org/sites/default/files/uploads/8597%20Adlai%20E%20Stevenson%20High%20School.pdf) was from Adlai E Stevenson HS.  We examine their solution.

To do so, we first realize that the information given to us on sheet 2 of the Excel sheet will be our guiding data. 
```{r}
npsMSL2
```

They make the following assumption for their model (justified by an article from National Geographic).  A rise of greater than 1 foot (304.8 mm) in a century represents High Risk.  A rise of greater than 0.3 feet (91.44 mm) in a century represents Medium Risk.  Anything less is Low Risk.

They then try to figure out the probability that a particular location will have a rise greater than these risk levels.  To do so, they assume a normal distribution of the MSL Trend Value.  First, they need to find the standard deviation from the 95% confidence interval that is given.  A 95% confidence interval for a standard normal distribution corresponds to the interval (-1.96, 1.96).

```{r}
qnorm(.025, mean = 0, sd = 1)
qnorm(.975, mean = 0, sd = 1)
```

Thus, they need to figure out the corresponding situation in their case using these values.  For Acadia NP, this looks like

```{r}
mu <- 2.178
sd <- (2.4 - mu)/qnorm(.975, mean = 0, sd = 1)
sd
```

Now, looking at the rise in sea levels over the next 10 years.  We would expect them to rise 2.178 mm/year * 10 years = 21.78 mm.  However, the sea level trend is probabilistic, so we need to take this into account.  We do so by developing a new normal distribution with mean = 2.178 * 10 and standard deviation = 0.1132674 * 10^.5.  (Why is this the case?  See this [article](https://www.statlect.com/probability-distributions/normal-distribution-linear-combinations).)

We can see this in the following calculation.  For a rise of 2.178 mm/year, we would expect ~42 years to reach the threshold of 91.44 mm.  Looking at the probabilities after 42 years.


```{r}
t <- 42
"Low Risk"
print(pnorm(91.44, mean = mu*t, sd = sd*t^.5))
"Med Risk"
print(pnorm(300.8, mean = mu*t, sd = sd*t^.5) - pnorm(91.44, mean = mu*t, sd = sd*t^.5))
"High Risk"
print(1 - pnorm(300.8, mean = mu*t, sd = sd*t^.5))
```


So, now to calculate the probabilites of risk for the assigned years (10, 20, 50, and 100).

```{r}

dfRisk <- as.data.frame(matrix(NA, nrow = 20, ncol = 5))
colnames(dfRisk) <- c("Station", "Years", "Low", "Med", "High")
count <- 1
str(dfRisk)
for(i in 2:ncol(npsMSL2)){
  station <- as.character(npsMSL2[2,i])
  mu <- as.numeric(npsMSL2[4,i])
  sd <- (as.numeric(npsMSL2[3,i]) - mu)/qnorm(0.975)
  for(t in c(10,20,50,100)) {
    dfRisk$Years[count] <- t
    dfRisk$Station[count] <- station
    dfRisk$Low[count] <- round(pnorm(91.44, mean = mu*t, sd = sd*t^.5),3)
    dfRisk$Med[count] <- round(pnorm(300.8, mean = mu*t, sd = sd*t^.5) - pnorm(91.44, mean = mu*t, sd = sd*t^.5),3)
    dfRisk$High[count] <- round(1 - pnorm(300.8, mean = mu*t, sd = sd*t^.5), 3)
    count <- count + 1
  }
}

dfRisk

```

The team then picked the risk rating with the highest probability as the rating for that year.





